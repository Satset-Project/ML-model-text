# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FI6aqaHi02KF9K2N4Dk7w3svwf9obIQD
"""

import pandas as pd
data = pd.read_excel('/content/training.xlsx')

df=data

df

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Prepare the tokenizer
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['Sentence'])

# Convert text to sequences
sequences = tokenizer.texts_to_sequences(df['Sentence'])
max_sequence_length = max(len(seq) for seq in sequences)
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')

# Prepare the labels
category_labels = pd.get_dummies(df['Category']).values
solution_labels = pd.get_dummies(df['Solution']).values

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate

# Define the input
input_ = Input(shape=(max_sequence_length,))

# Embedding layer
embedding = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length)(input_)

# LSTM layer
lstm = LSTM(128)(embedding)

# Dense layers for category and action predictions
category_output = Dense(len(df['Category'].unique()), activation='softmax', name='category_output')(lstm)
solution_output = Dense(len(df['Solution'].unique()), activation='softmax', name='solution_output')(lstm)

# Combine the model
model = Model(inputs=input_, outputs=[category_output, solution_output])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Split the data into training and validation sets
from sklearn.model_selection import train_test_split

X_train, X_val, y_train_category, y_val_category, y_train_solution, y_val_solution = train_test_split(
    padded_sequences, category_labels, solution_labels, test_size=0.2, random_state=42
)

# Train the model
history = model.fit(
    X_train,
    {'category_output': y_train_category, 'solution_output': y_train_solution},
    validation_data=(X_val, {'category_output': y_val_category, 'solution_output': y_val_solution}),
    epochs=100,
    batch_size=32
)

"""Generate Responses"""

import numpy as np

def generate_response(description):
    # Preprocess the input description
    description_sequence = tokenizer.texts_to_sequences([description])
    description_padded = pad_sequences(description_sequence, maxlen=max_sequence_length, padding='post')

    # Predict using the model
    category_prob, solution_prob = model.predict(description_padded)

    # Get the predicted category and solution
    predicted_category = np.argmax(category_prob)
    predicted_solution = np.argmax(solution_prob)

    # Map indices back to category and solution labels
    category_label = df['Category'].unique()[predicted_category]
    solution_label = df['Solution'].unique()[predicted_solution]

    # Prepare the response
    response = f"For the issue, our recommendation is to check '{category_label}' and consider '{solution_label}'."

    return response

# Test the function
description = input("Please describe your issue: ")
response = generate_response(description)
print(response)

"""Save Model"""

model.save("issue_classification_model.h5")

# Verify the saved model
loaded_model = tf.keras.models.load_model("issue_classification_model.h5")
print("Model loaded successfully and is ready for use.")

